{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generating refactored corpus\n",
    "Modify the synthetic benchmarks to generate a corpus of refactored programs.\n",
    "Generate 1 refactored program for each benchmark version."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import refactorings\n",
    "from pathlib import Path\n",
    "import difflib\n",
    "import random\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin experiment\n",
    "\n",
    "Subject benchmarks:\n",
    "- ABM\n",
    "- C Test Suite\n",
    "\n",
    "Hyperparameters:\n",
    "- random seed\n",
    "- num_iterations: Number of transformations to do\n",
    "- transforms:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from contextlib import redirect_stdout\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict\n",
    "\n",
    "# Experiment parameters\n",
    "picker = refactorings.random_picker\n",
    "transforms = refactorings.all_refactorings\n",
    "\n",
    "factory = refactorings.TransformationsFactory(transforms, picker)\n",
    "\n",
    "def store_file(new, old):\n",
    "    shutil.copy(new, old)\n",
    "    diff = list(difflib.unified_diff(old.open().readlines(), new.open().readlines(), fromfile=c_file.name, tofile=c_file.name))\n",
    "    with open(str(c_file) + '.diff', 'w') as f:\n",
    "        f.write(''.join(diff))\n",
    "\n",
    "def get_file(project):\n",
    "    c_files = list(project.glob('**/*.c'))\n",
    "    c_files = [c for c in c_files if not c.name.endswith('.formatted.c') and not c.name.endswith('.new.c')]\n",
    "    assert len(c_files) >= 1, f'No C files found in {project}'\n",
    "\n",
    "    if len(c_files) == 1:\n",
    "        c_file = c_files[0]\n",
    "    elif len(c_files) > 1:\n",
    "        # print(c_files)\n",
    "        for fpath in c_files:\n",
    "            with fpath.open() as f:\n",
    "                text = f.read()\n",
    "            import re\n",
    "            if re.search(r'/\\*\\s*BAD\\s*\\*/', text) or re.search(r'/\\*\\s*FLAW\\s*\\*/', text):\n",
    "                c_file = fpath\n",
    "    return c_file\n",
    "\n",
    "# This file contains all the buggy versions from the synthetic benchmarks with the format \"project-version\".\n",
    "# One sample per line.\n",
    "# df = pd.read_csv('logs/synthetic-samples.csv', dtype=str)\n",
    "# df = pd.read_csv('logs/toyota.csv', dtype=str)\n",
    "df = pd.read_csv('logs/zitser.csv', dtype=str)\n",
    "# df = pd.read_csv('failed-crlf-real.csv', dtype=str)\n",
    "samples = list(zip(df[\"project\"], df[\"version\"]))\n",
    "tests = Path('tests')\n",
    "all_projects = [tests / p / v for p,v in samples]\n",
    "samples_by_project = defaultdict(list)\n",
    "for p, v in samples:\n",
    "    project = tests / p / v\n",
    "    assert project.exists()\n",
    "    if 'itc' in str(project):\n",
    "        for c_file in project.glob('**/*.c'):\n",
    "            samples_by_project[p].append((project,c_file))\n",
    "    else:\n",
    "        c_file = get_file(project)\n",
    "        samples_by_project[p].append((project,c_file))\n",
    "\n",
    "logfile = Path('log.txt')\n",
    "if logfile.exists():\n",
    "    logfile.unlink()\n",
    "if Path('errors.log').exists():\n",
    "    Path('errors.log').unlink()\n",
    "\n",
    "failed_df = pd.read_csv('logs/manual.csv', dtype=str)\n",
    "\n",
    "def get_exclude(bench_name, project, c_file):\n",
    "    \"\"\"Return the exclude pattern given a benchmark name, project directory and target C file.\"\"\"\n",
    "    # print(bench_name, project, c_file)\n",
    "    if bench_name == 'itc':\n",
    "        from shutil import ignore_patterns\n",
    "        srcdir = project / 'src'\n",
    "        srcfiles = list(str(f.relative_to(srcdir)) for f in srcdir.glob('*.c') if f.name != c_file.name)\n",
    "        # print(srcfiles)\n",
    "        return ignore_patterns(*srcfiles)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# projects = [p for p in projects if s == 'ctestsuite' and p.name == '111']\n",
    "# projects = [p for p in projects if any(s == row[\"project\"] and p.name == row[\"version\"] for i, row in failed_df.iterrows())]\n",
    "print(f'Redirecting stdout to {logfile}')\n",
    "for benchmark_name, projects_and_files in samples_by_project.items():\n",
    "    for project, c_file in tqdm_notebook(projects_and_files, desc=b):\n",
    "        random.seed(0)\n",
    "        with open(logfile, 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                exclude = get_exclude(benchmark_name, project, c_file)\n",
    "                shutil.copy(c_file, c_file.parent / (c_file.name + '.back'))\n",
    "                with factory.make_project(c_file, project, exclude) as project:\n",
    "                    print('***REFACTORING***', project, c_file)\n",
    "                    tmp_c_file = project.apply_all()\n",
    "                    new_c_file = Path(str(c_file) + '.reformat')\n",
    "                    store_file(tmp_c_file, c_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loaded (['insert_noop', 'loop_exchange', 'permute_stmt', 'rename_variable', 'switch_exchange'])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Redirecting stdout to log.txt\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='zitser', max=14, style=ProgressStyle(description_width='initiâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df3aa98d18548ea9697c0f182b91e3c",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "all_transform_names = sorted([t.__name__ for t in transforms])\n",
    "\n",
    "with open('logs/stats.csv', 'w') as csv_f:\n",
    "    print(','.join(('project', 'version', *all_transform_names, 'lines changed')), file=csv_f)\n",
    "\n",
    "    tests = Path('tests')\n",
    "    df = pd.read_csv('logs/synthetic-samples.csv', dtype=str)\n",
    "    for i, row in df.iterrows():\n",
    "        # Get files and check they exist\n",
    "        try:\n",
    "            home = tests / row[\"project\"] / str(row[\"version\"])\n",
    "            transforms_file = next(home.glob('*.transforms.txt'))\n",
    "            old_file = next(transforms_file.parent.glob('*.c.reformat'))\n",
    "            new_file = old_file.parent / old_file.stem\n",
    "            assert transforms_file.exists()\n",
    "            assert old_file.exists()\n",
    "            assert new_file.exists()\n",
    "        except:\n",
    "            print('Error', row[\"project\"], row[\"version\"])\n",
    "            raise\n",
    "\n",
    "        # Collect which transforms were applied\n",
    "        with open(transforms_file) as f:\n",
    "            transforms_applied = set(f.read().splitlines())\n",
    "        was_applied = [t in transforms_applied for t in all_transform_names]\n",
    "\n",
    "        # Collect number of changed lines\n",
    "        differences = sum(1 for d in difflib.ndiff(old_file.open().readlines(), new_file.open().readlines()) if d[0] in ('+', '-'))\n",
    "\n",
    "        print(','.join((row[\"project\"], str(row[\"version\"]), *('TRUE' if a else 'FALSE' for a in was_applied), str(differences))), file=csv_f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import shutil\n",
    "\n",
    "# df = pd.read_csv('logs/synthetic-samples.csv', dtype=str)\n",
    "df = pd.read_csv('logs/zitser.csv', dtype=str)\n",
    "# df = pd.read_csv('manual.csv', dtype=str)\n",
    "tests = Path('tests')\n",
    "exclude = []\n",
    "failed = []\n",
    "for i, row in tqdm.tqdm_notebook(list(df.iterrows())):\n",
    "    project, version = row[\"project\"], row[\"version\"]\n",
    "    code_dir = tests / project / version\n",
    "    assert code_dir.exists()\n",
    "\n",
    "    refactored = next(code_dir.glob('*.c.reformat'))\n",
    "    original = refactored.parent / refactored.stem\n",
    "    backup = refactored.parent / (refactored.stem + '.back')\n",
    "    assert refactored.exists(), refactored\n",
    "    assert original.exists(), original\n",
    "    assert backup.exists(), backup\n",
    "    \n",
    "    makefile = refactored.parent / 'Makefile'\n",
    "    assert makefile.exists()\n",
    "    makefile_backup = refactored.parent / 'Makefile.okbad'\n",
    "    if not makefile_backup.exists():\n",
    "        shutil.copy2(makefile, makefile_backup)\n",
    "    with open(makefile) as f:\n",
    "        text = f.read()\n",
    "    import re\n",
    "    text = re.sub(r'(\\w+)-ok', r'\\1', text)\n",
    "    text = re.sub(r'(\\w+)-bad', r'\\1', text)\n",
    "    with open(makefile, 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "    # Check return code\n",
    "    proc = subprocess.run('make clean', cwd=str(code_dir), shell=True)\n",
    "    proc = subprocess.run('make', cwd=str(code_dir), capture_output=True, shell=True)\n",
    "    if proc.returncode != 0:\n",
    "        exclude.append((project, version, proc.stderr.decode()))\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        shutil.copy(refactored, original)\n",
    "        original.touch()\n",
    "        proc = subprocess.run('make clean', cwd=str(code_dir), shell=True)\n",
    "        proc = subprocess.run('make', cwd=str(code_dir), capture_output=True, shell=True)\n",
    "        if proc.returncode != 0:\n",
    "            failed.append((project, version, proc.stderr.decode()))\n",
    "    finally:\n",
    "        shutil.copy(backup, original)\n",
    "\n",
    "# install mysql-devel and pam-devel first.\n",
    "# Some projects in ctestsuite won't build.\n",
    "print(len(exclude), 'versions didn\\'t build')\n",
    "with open('logs/exclude.csv', 'w') as f:\n",
    "    f.write(f'project,version\\n')\n",
    "    for project, version, e in exclude:\n",
    "        f.write(f'{project},{version}\\n')\n",
    "with open('logs/exclude.txt', 'w') as f:\n",
    "    for project, version, e in exclude:\n",
    "        f.write(f'***tests/{project}/{version}***\\n')\n",
    "        f.write(f'{e}\\n')\n",
    "\n",
    "print(len(failed), 'versions failed after refactoring')\n",
    "with open('logs/failed.csv', 'w') as f:\n",
    "    f.write(f'project,version\\n')\n",
    "    for project, version, e in failed:\n",
    "        f.write(f'{project},{version}\\n')\n",
    "with open('logs/failed.log', 'w') as f:\n",
    "    for project, version, e in failed:\n",
    "        f.write(f'***tests/{project}/{version}***\\n')\n",
    "        f.write(f'{e}\\n')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8c89a6cbd4eaaa104f4b7fcdff6a7",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "1 versions didn't build\n",
      "1 versions failed after refactoring\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To pack up refactorings, use `tar cf refactors.tar $(find itc -name '*.c.reformat' -o -name '*.c.diff' -o -name '*.transforms.txt')`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Look for ground truth\n",
    "Ground truth means:\n",
    "1. Buggy and OK versions both have some flaw location matching with the meta-alerts in the DB\n",
    "2. Of the meta-alerts matched to flaw locations, buggy and OK should share conditions for at least 1 meta-alert."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import projectslib.projects\n",
    "import projectslib.corebench_groundtruth\n",
    "import re\n",
    "# Analyze ground truth\n",
    "\n",
    "corebench_project_names = ['make', 'grep', 'coreutils', 'findutils']\n",
    "project_filter = []\n",
    "project_filter += ['abm', 'ctestsuite', 'zitser', 'toyota']\n",
    "# project_filter += corebench_project_names\n",
    "projects = projectslib.projects.get(project_filter)\n",
    "print(len(projects))\n",
    "\n",
    "corebench_manual_groundtruth = projectslib.corebench_groundtruth.get(projects)\n",
    "for proj in projects:\n",
    "    if proj.program in corebench_manual_groundtruth:\n",
    "        flaws = corebench_manual_groundtruth[proj.program][proj.buggy]\n",
    "    else:\n",
    "        flaws = set()\n",
    "        files = list(proj.buggy_path.glob('**/*.c') + proj.buggy_path.glob('*.c'))\n",
    "        assert len(files) > 0, proj.buggy_path\n",
    "        for fname in files:\n",
    "            with open(fname) as f:\n",
    "                for i, line in enumerate(f.readlines(), start=1):\n",
    "                    if proj.program in 'abm':\n",
    "                        if re.search(r'/\\*\\s*BAD\\s*\\*/', line):\n",
    "                            flaws.add((fname, int(i)))\n",
    "                    elif proj.program == 'zitser':\n",
    "                        if re.search(r'/\\*\\s*BAD\\s*\\*/', line):\n",
    "                            flaws.add((fname, int(i+1)))\n",
    "                    elif proj.program == 'ctestsuite':\n",
    "                        if re.search(r'/\\*\\s*FLAW\\s*\\*/', line):\n",
    "                            flaws.add((fname, int(i)))\n",
    "                    elif proj.program == 'toyota':\n",
    "                        if re.search(r'/\\*\\s*ERROR', line):\n",
    "                            flaws.add((fname, int(i)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "127\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "3fc56e3fab8c747237b055ef0e7d2321d1637d9af88e6fee51f2ecb6862cb686"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}