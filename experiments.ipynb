{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generating refactored corpus\n",
    "Modify the synthetic benchmarks to generate a corpus of refactored programs.\n",
    "Generate 1 refactored program for each benchmark version."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import refactorings\n",
    "import projectslib\n",
    "from pathlib import Path\n",
    "import difflib\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import random"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Look for ground truth\n",
    "Ground truth means:\n",
    "1. Buggy and OK versions both have some flaw location matching with the meta-alerts in the DB\n",
    "2. Of the meta-alerts matched to flaw locations, buggy and OK should share conditions for at least 1 meta-alert."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "corebench_project_names = ['make', 'grep', 'coreutils', 'findutils']\n",
    "project_filter = []\n",
    "project_filter += ['abm', 'ctestsuite', 'zitser', 'toyota']\n",
    "# project_filter += corebench_project_names\n",
    "projects = projectslib.get_projects(project_filter)\n",
    "len(projects)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin experiment\n",
    "\n",
    "Subject benchmarks:\n",
    "- ABM\n",
    "- C Test Suite\n",
    "\n",
    "Hyperparameters:\n",
    "- random seed\n",
    "- num_iterations: Number of transformations to do\n",
    "- transforms:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from contextlib import redirect_stdout\n",
    "from tqdm import tqdm_notebook\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from shutil import ignore_patterns\n",
    "\n",
    "# Experiment parameters\n",
    "picker = refactorings.random_picker\n",
    "transforms = refactorings.all_refactorings\n",
    "factory = refactorings.TransformationsFactory(transforms, picker)\n",
    "\n",
    "# Zonk existing log files\n",
    "logfile = Path('log.txt')\n",
    "if logfile.exists():\n",
    "    logfile.unlink()\n",
    "if Path('errors.log').exists():\n",
    "    Path('errors.log').unlink()\n",
    "\n",
    "\n",
    "def get_exclude(bench_name, project, c_file):\n",
    "    \"\"\"Return the exclude pattern given a benchmark name, project directory and target C file.\"\"\"\n",
    "    if bench_name == 'itc':\n",
    "        srcfiles = list(str(f.relative_to(project)) for f in project.walk('*.c') if f.name != c_file.name and f.name != 'main.c')\n",
    "        srcfiles += project.walk('*.c.diff')\n",
    "        srcfiles += project.walk('*.c.back')\n",
    "        srcfiles += project.walk('*.c.refactor')\n",
    "        srcfiles += project.walk('*.c.transforms')\n",
    "        return ignore_patterns(*srcfiles)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def proj_and_files(proj):\n",
    "    result = set()\n",
    "    for f, _ in proj.flaws:\n",
    "        result.add((proj, f))\n",
    "    return list(result)\n",
    "\n",
    "\n",
    "print(f'Redirecting stdout to {logfile}')\n",
    "for project_name in sorted(list(set(p.program for p in projects))):\n",
    "    projects_and_files = []\n",
    "    for p in projects:\n",
    "        if p.program == project_name:\n",
    "            result = set()\n",
    "            for f, _ in p.flaws:\n",
    "                result.add((p, f))\n",
    "            projects_and_files.extend(result)\n",
    "    projects_and_files = sorted(projects_and_files, key=lambda p: str(p[1]))\n",
    "    for proj, c_file in tqdm_notebook(projects_and_files, desc=project_name):\n",
    "        avoid = []\n",
    "        for f, lineno in proj.flaws:\n",
    "            if f == c_file:\n",
    "                avoid.append(lineno)\n",
    "        assert len(avoid) > 0\n",
    "        random.seed(0)\n",
    "        with open(logfile, 'a') as f:\n",
    "            with redirect_stdout(f):\n",
    "                exclude = get_exclude(proj.program, proj.buggy_path, c_file)\n",
    "                with factory.make_project(c_file, proj.buggy_path, exclude, avoid=avoid) as refactoring_project:\n",
    "                    print('***REFACTORING***', refactoring_project, c_file)\n",
    "                    tmp_c_file, transforms_applied = refactoring_project.apply_all(return_applied=True)\n",
    "                    new_c_file = Path(str(c_file) + '.refactor')\n",
    "                    shutil.copy(tmp_c_file, new_c_file)\n",
    "                    with open(c_file.parent / (c_file.name + '.transforms'), 'w') as f:\n",
    "                        f.write('\\n'.join(t.__name__ for t in transforms_applied))\n",
    "                    with open(c_file) as old_f, open(new_c_file) as new_f:\n",
    "                        diff = list(difflib.unified_diff(old_f.readlines(), new_f.readlines(), fromfile=c_file.name, tofile=c_file.name))\n",
    "                    with open(str(c_file) + '.diff', 'w') as f:\n",
    "                        f.write(''.join(diff))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'refactorings' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2081064/3407659028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Experiment parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpicker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefactorings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_picker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefactorings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_refactorings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefactorings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformationsFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpicker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'refactorings' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "all_transform_names = sorted([t.__name__ for t in refactorings.all_refactorings])\n",
    "\n",
    "with open('stats.csv', 'w') as csv_f:\n",
    "    print(','.join(('project', 'version', *all_transform_names, 'lines changed')), file=csv_f)\n",
    "    for proj in projects:\n",
    "        # Get files and check they exist\n",
    "        try:\n",
    "            transforms_file = next(proj.buggy_path.walk('*.c.transforms'))\n",
    "            new_file = transforms_file.with_suffix('.refactor')\n",
    "            old_file = new_file.parent / new_file.stem\n",
    "        except:\n",
    "            raise Exception(f'{proj.program}-{proj.buggy}')\n",
    "        assert transforms_file.exists()\n",
    "        assert new_file.exists(), new_file\n",
    "        assert old_file.exists(), old_file\n",
    "\n",
    "        # Collect which transforms were applied\n",
    "        with open(transforms_file) as f:\n",
    "            transforms_applied = set(f.read().splitlines())\n",
    "        was_applied = [t in transforms_applied for t in all_transform_names]\n",
    "\n",
    "        # Collect number of changed lines\n",
    "        differences = sum(1 for d in difflib.ndiff(old_file.open().readlines(), new_file.open().readlines()) if d[0] in ('+', '-'))\n",
    "\n",
    "        print(','.join((proj.program, proj.buggy, *('TRUE' if a else 'FALSE' for a in was_applied), str(differences))), file=csv_f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "exclude = []\n",
    "failed = []\n",
    "# for i, row in tqdm.tqdm_notebook(list(df.iterrows())):\n",
    "for proj in projects:\n",
    "    project = proj.program\n",
    "    for version, code_dir in zip((proj.buggy, proj.ok), (proj.buggy_path, proj.ok_path)):\n",
    "        assert code_dir.exists()\n",
    "\n",
    "        # Replace refactored file\n",
    "        refactored = next(code_dir.glob('*.c.refactor'))\n",
    "        original = refactored.parent / refactored.stem\n",
    "        backup = refactored.parent / (refactored.stem + '.back')\n",
    "        assert refactored.exists(), refactored\n",
    "        assert original.exists(), original\n",
    "        if not backup.exists():\n",
    "            shutil.copy2(original, backup)\n",
    "        assert backup.exists(), backup\n",
    "        \n",
    "        # Fix up the makefile which might reference the *-ok/*-bad filenames\n",
    "        makefile = refactored.parent / 'Makefile'\n",
    "        assert makefile.exists()\n",
    "        makefile_backup = refactored.parent / 'Makefile.okbad'\n",
    "        if not makefile_backup.exists():\n",
    "            shutil.copy2(makefile, makefile_backup)\n",
    "        with open(makefile) as f:\n",
    "            text = f.read()\n",
    "        text = re.sub(r'(\\w+)-ok', r'\\1', text)\n",
    "        text = re.sub(r'(\\w+)-bad', r'\\1', text)\n",
    "        with open(makefile, 'w') as f:\n",
    "            f.write(text)\n",
    "\n",
    "        # Build and check\n",
    "        proc = subprocess.run('make clean', cwd=str(code_dir), shell=True)\n",
    "        proc = subprocess.run('make', cwd=str(code_dir), capture_output=True, shell=True)\n",
    "        if proc.returncode != 0:\n",
    "            exclude.append((project, version, proc.stderr.decode()))\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            shutil.copy(refactored, original)\n",
    "            original.touch()\n",
    "            proc = subprocess.run('make clean', cwd=str(code_dir), shell=True)\n",
    "            proc = subprocess.run('make', cwd=str(code_dir), capture_output=True, shell=True)\n",
    "            if proc.returncode != 0:\n",
    "                failed.append((project, version, proc.stderr.decode()))\n",
    "        finally:\n",
    "            shutil.copy(backup, original)\n",
    "\n",
    "# install mysql-devel and pam-devel first.\n",
    "# Some projects in ctestsuite won't build.\n",
    "print(len(exclude), 'versions didn\\'t build')\n",
    "with open('logs/exclude.csv', 'w') as f:\n",
    "    f.write(f'project,version\\n')\n",
    "    for project, version, e in exclude:\n",
    "        f.write(f'{project},{version}\\n')\n",
    "with open('logs/exclude.txt', 'w') as f:\n",
    "    for project, version, e in exclude:\n",
    "        f.write(f'***tests/{project}/{version}***\\n')\n",
    "        f.write(f'{e}\\n')\n",
    "\n",
    "print(len(failed), 'versions failed after refactoring')\n",
    "with open('logs/failed.csv', 'w') as f:\n",
    "    f.write(f'project,version\\n')\n",
    "    for project, version, e in failed:\n",
    "        f.write(f'{project},{version}\\n')\n",
    "with open('logs/failed.log', 'w') as f:\n",
    "    for project, version, e in failed:\n",
    "        f.write(f'***tests/{project}/{version}***\\n')\n",
    "        f.write(f'{e}\\n')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8c89a6cbd4eaaa104f4b7fcdff6a7",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "1 versions didn't build\n",
      "1 versions failed after refactoring\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To pack up refactorings, use `tar cf refactors.tar $(find itc -name '*.c.reformat' -o -name '*.c.diff' -o -name '*.transforms.txt')`."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "3fc56e3fab8c747237b055ef0e7d2321d1637d9af88e6fee51f2ecb6862cb686"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}